{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venture Funding with Deep Learning\n",
    "\n",
    "You work as a risk management associate at Alphabet Soup, a venture capital firm. Alphabet Soup’s business team receives many funding applications from startups every day. This team has asked you to help them create a model that predicts whether applicants will be successful if funded by Alphabet Soup.\n",
    "\n",
    "The business team has given you a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. With your knowledge of machine learning and neural networks, you decide to use the features in the provided dataset to create a binary classifier model that will predict whether an applicant will become a successful business. The CSV file contains a variety of information about these businesses, including whether or not they ultimately became successful.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "The steps for this challenge are broken out into the following sections:\n",
    "\n",
    "* Prepare the data for use on a neural network model.\n",
    "\n",
    "* Compile and evaluate a binary classification model using a neural network.\n",
    "\n",
    "* Optimize the neural network model.\n",
    "\n",
    "### Prepare the Data for Use on a Neural Network Model \n",
    "\n",
    "Using your knowledge of Pandas and scikit-learn’s `StandardScaler()`, preprocess the dataset so that you can use it to compile and evaluate the neural network model later.\n",
    "\n",
    "Open the starter code file, and complete the following data preparation steps:\n",
    "\n",
    "1. Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.   \n",
    "\n",
    "2. Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model.\n",
    " \n",
    "3. Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame.\n",
    "\n",
    "4. Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. \n",
    "\n",
    "5. Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
    "\n",
    "6. Split the features and target sets into training and testing datasets.\n",
    "\n",
    "7. Use scikit-learn's `StandardScaler` to scale the features data.\n",
    "\n",
    "### Compile and Evaluate a Binary Classification Model Using a Neural Network\n",
    "\n",
    "Use your knowledge of TensorFlow to design a binary classification deep neural network model. This model should use the dataset’s features to predict whether an Alphabet Soup&ndash;funded startup will be successful based on the features in the dataset. Consider the number of inputs before determining the number of layers that your model will contain or the number of neurons on each layer. Then, compile and fit your model. Finally, evaluate your binary classification model to calculate the model’s loss and accuracy. \n",
    " \n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n",
    "\n",
    "2. Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n",
    "\n",
    "> **Hint** When fitting the model, start with a small number of epochs, such as 20, 50, or 100.\n",
    "\n",
    "3. Evaluate the model using the test data to determine the model’s loss and accuracy.\n",
    "\n",
    "4. Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n",
    "\n",
    "### Optimize the Neural Network Model\n",
    "\n",
    "Using your knowledge of TensorFlow and Keras, optimize your model to improve the model's accuracy. Even if you do not successfully achieve a better accuracy, you'll need to demonstrate at least two attempts to optimize the model. You can include these attempts in your existing notebook. Or, you can make copies of the starter notebook in the same folder, rename them, and code each model optimization in a new notebook. \n",
    "\n",
    "> **Note** You will not lose points if your model does not achieve a high accuracy, as long as you make at least two attempts to optimize the model.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Define at least three new deep neural network models (the original plus 2 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n",
    "\n",
    "2. After finishing your models, display the accuracy scores achieved by each model, and compare the results.\n",
    "\n",
    "3. Save each of your models as an HDF5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Apple Silicon (M1) machine, created virtual environment for machine learning and tensorflow libraries, including tensorflow-metal, according to Apple's recommendations:\n",
    "# https://developer.apple.com/metal/tensorflow-plugin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare the data to be used on a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   EIN                     34299 non-null  int64 \n",
      " 1   NAME                    34299 non-null  object\n",
      " 2   APPLICATION_TYPE        34299 non-null  object\n",
      " 3   AFFILIATION             34299 non-null  object\n",
      " 4   CLASSIFICATION          34299 non-null  object\n",
      " 5   USE_CASE                34299 non-null  object\n",
      " 6   ORGANIZATION            34299 non-null  object\n",
      " 7   STATUS                  34299 non-null  int64 \n",
      " 8   INCOME_AMT              34299 non-null  object\n",
      " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 10  ASK_AMT                 34299 non-null  int64 \n",
      " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
    "applicant_data_df = pd.read_csv(Path('Resources/applicants_data.csv'))\n",
    "\n",
    "# Review the DataFrame\n",
    "display(applicant_data_df.info(), applicant_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIN                        int64\n",
      "NAME                      object\n",
      "APPLICATION_TYPE          object\n",
      "AFFILIATION               object\n",
      "CLASSIFICATION            object\n",
      "USE_CASE                  object\n",
      "ORGANIZATION              object\n",
      "STATUS                     int64\n",
      "INCOME_AMT                object\n",
      "SPECIAL_CONSIDERATIONS    object\n",
      "ASK_AMT                    int64\n",
      "IS_SUCCESSFUL              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "print(applicant_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the 'EIN' and 'NAME' columns from the DataFrame\n",
    "applicant_data_df = applicant_data_df.drop(columns=['EIN', 'NAME'])\n",
    "\n",
    "# Review the DataFrame\n",
    "display(applicant_data_df)\n",
    "# We have 9 features, or explanatory variables, and 1 target variable, in our final source dataset, prior to any encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of categorical variables, filtering out numerical fields and leaving categorical fields\n",
    "cat_variables = list(applicant_data_df.dtypes[applicant_data_df.dtypes=='object'].index)\n",
    "#categorical_variables = applicant_data_df.dtypes.loc[applicant_data_df.dtypes=='object'].index #Alternative formulation using .loc, does not appear advantageous\n",
    "\n",
    "# Display the categorical variables list\n",
    "display(cat_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION     INCOME_AMT SPECIAL_CONSIDERATIONS  \n",
       "0       Association              0                      N  \n",
       "1      Co-operative         1-9999                      N  \n",
       "2       Association              0                      N  \n",
       "3             Trust    10000-24999                      N  \n",
       "4             Trust  100000-499999                      N  \n",
       "...             ...            ...                    ...  \n",
       "34294   Association              0                      N  \n",
       "34295   Association              0                      N  \n",
       "34296   Association              0                      N  \n",
       "34297   Association              0                      N  \n",
       "34298  Co-operative          1M-5M                      N  \n",
       "\n",
       "[34299 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical DataFrame shape: (34299, 114)\n"
     ]
    }
   ],
   "source": [
    "# Review the applicant categorical DataFrame\n",
    "applicant_cat_data_df = applicant_data_df[cat_variables]\n",
    "display(applicant_cat_data_df)\n",
    "\n",
    "# Encode the categorical DataFrame using OneHotEncoder\n",
    "applicant_cat_data_encoded = encoder.fit_transform(applicant_cat_data_df)\n",
    "print(f\"Categorical DataFrame shape: {applicant_cat_data_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>APPLICATION_TYPE_T25</th>\n",
       "      <th>APPLICATION_TYPE_T29</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
       "0                       1.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                   0.0                   0.0                   0.0   \n",
       "34295                   0.0                   0.0                   0.0   \n",
       "34296                   0.0                   0.0                   0.0   \n",
       "34297                   0.0                   0.0                   0.0   \n",
       "34298                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                   0.0                   0.0                   0.0   \n",
       "34295                   0.0                   0.0                   0.0   \n",
       "34296                   0.0                   0.0                   0.0   \n",
       "34297                   0.0                   0.0                   0.0   \n",
       "34298                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
       "0                       0.0                  0.0                   0.0   \n",
       "1                       0.0                  0.0                   0.0   \n",
       "2                       0.0                  0.0                   0.0   \n",
       "3                       0.0                  0.0                   0.0   \n",
       "4                       0.0                  0.0                   0.0   \n",
       "...                     ...                  ...                   ...   \n",
       "34294                   0.0                  0.0                   0.0   \n",
       "34295                   0.0                  0.0                   0.0   \n",
       "34296                   0.0                  0.0                   0.0   \n",
       "34297                   0.0                  0.0                   0.0   \n",
       "34298                   0.0                  0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T29  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                       0.0  ...                0.0                     0.0   \n",
       "1                       0.0  ...                1.0                     0.0   \n",
       "2                       0.0  ...                0.0                     0.0   \n",
       "3                       0.0  ...                0.0                     1.0   \n",
       "4                       0.0  ...                0.0                     0.0   \n",
       "...                     ...  ...                ...                     ...   \n",
       "34294                   0.0  ...                0.0                     0.0   \n",
       "34295                   0.0  ...                0.0                     0.0   \n",
       "34296                   0.0  ...                0.0                     0.0   \n",
       "34297                   0.0  ...                0.0                     0.0   \n",
       "34298                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                           0.0                 0.0               0.0   \n",
       "1                           0.0                 0.0               0.0   \n",
       "2                           0.0                 0.0               0.0   \n",
       "3                           0.0                 0.0               0.0   \n",
       "4                           1.0                 0.0               0.0   \n",
       "...                         ...                 ...               ...   \n",
       "34294                       0.0                 0.0               0.0   \n",
       "34295                       0.0                 0.0               0.0   \n",
       "34296                       0.0                 0.0               0.0   \n",
       "34297                       0.0                 0.0               0.0   \n",
       "34298                       0.0                 0.0               1.0   \n",
       "\n",
       "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                         0.0              0.0                0.0   \n",
       "1                         0.0              0.0                0.0   \n",
       "2                         0.0              0.0                0.0   \n",
       "3                         0.0              0.0                0.0   \n",
       "4                         0.0              0.0                0.0   \n",
       "...                       ...              ...                ...   \n",
       "34294                     0.0              0.0                0.0   \n",
       "34295                     0.0              0.0                0.0   \n",
       "34296                     0.0              0.0                0.0   \n",
       "34297                     0.0              0.0                0.0   \n",
       "34298                     0.0              0.0                0.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           1.0                       0.0  \n",
       "1                           1.0                       0.0  \n",
       "2                           1.0                       0.0  \n",
       "3                           1.0                       0.0  \n",
       "4                           1.0                       0.0  \n",
       "...                         ...                       ...  \n",
       "34294                       1.0                       0.0  \n",
       "34295                       1.0                       0.0  \n",
       "34296                       1.0                       0.0  \n",
       "34297                       1.0                       0.0  \n",
       "34298                       1.0                       0.0  \n",
       "\n",
       "[34299 rows x 114 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "applicant_cat_data_encoded_df = pd.DataFrame(applicant_cat_data_encoded.todense(), columns=encoder.get_feature_names_out(cat_variables)) # 'todense() required as it appears pandas requires dense, not sparse input\n",
    "\n",
    "# Review the DataFrame\n",
    "display(applicant_cat_data_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  \\\n",
       "0           1      5000              1                   1.0   \n",
       "1           1    108590              1                   0.0   \n",
       "2           1      5000              0                   0.0   \n",
       "3           1      6692              1                   0.0   \n",
       "4           1    142590              1                   0.0   \n",
       "...       ...       ...            ...                   ...   \n",
       "34294       1      5000              0                   0.0   \n",
       "34295       1      5000              0                   0.0   \n",
       "34296       1      5000              0                   0.0   \n",
       "34297       1      5000              1                   0.0   \n",
       "34298       1  36500179              0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                   0.0                   0.0                   0.0   \n",
       "34295                   0.0                   0.0                   0.0   \n",
       "34296                   0.0                   0.0                   0.0   \n",
       "34297                   0.0                   0.0                   0.0   \n",
       "34298                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  ...  \\\n",
       "0                       0.0                   0.0                   0.0  ...   \n",
       "1                       0.0                   0.0                   0.0  ...   \n",
       "2                       0.0                   0.0                   0.0  ...   \n",
       "3                       0.0                   0.0                   0.0  ...   \n",
       "4                       0.0                   0.0                   0.0  ...   \n",
       "...                     ...                   ...                   ...  ...   \n",
       "34294                   0.0                   0.0                   0.0  ...   \n",
       "34295                   0.0                   0.0                   0.0  ...   \n",
       "34296                   0.0                   0.0                   0.0  ...   \n",
       "34297                   0.0                   0.0                   0.0  ...   \n",
       "34298                   0.0                   0.0                   0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    1.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     1.0                       0.0   \n",
       "4                    0.0                     0.0                       1.0   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                0.0                     0.0                       0.0   \n",
       "34295                0.0                     0.0                       0.0   \n",
       "34296                0.0                     0.0                       0.0   \n",
       "34297                0.0                     0.0                       0.0   \n",
       "34298                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                 0.0               0.0                     0.0   \n",
       "34295                 0.0               0.0                     0.0   \n",
       "34296                 0.0               0.0                     0.0   \n",
       "34297                 0.0               0.0                     0.0   \n",
       "34298                 0.0               1.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "...                ...                ...                       ...   \n",
       "34294              0.0                0.0                       1.0   \n",
       "34295              0.0                0.0                       1.0   \n",
       "34296              0.0                0.0                       1.0   \n",
       "34297              0.0                0.0                       1.0   \n",
       "34298              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "34294                       0.0  \n",
       "34295                       0.0  \n",
       "34296                       0.0  \n",
       "34297                       0.0  \n",
       "34298                       0.0  \n",
       "\n",
       "[34299 rows x 117 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame for numerical fields only\n",
    "applicant_num_data_df = applicant_data_df.drop(columns=cat_variables)\n",
    "#display(applicant_num_data_df)\n",
    "\n",
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "applicant_encoded_df = pd.concat([applicant_num_data_df, applicant_cat_data_encoded_df], axis='columns')\n",
    "\n",
    "# Review the DataFrame\n",
    "display(applicant_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IS_SUCCESSFUL\n",
       "0                  1\n",
       "1                  1\n",
       "2                  0\n",
       "3                  1\n",
       "4                  1\n",
       "...              ...\n",
       "34294              0\n",
       "34295              0\n",
       "34296              0\n",
       "34297              1\n",
       "34298              0\n",
       "\n",
       "[34299 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IS_SUCCESSFUL\n",
       "1                18261\n",
       "0                16038\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a list for the target variable field name(s)\n",
    "y_target = ['IS_SUCCESSFUL']\n",
    "\n",
    "# Define the target set y using the IS_SUCCESSFUL column\n",
    "y = applicant_encoded_df[y_target]\n",
    "\n",
    "# Display a sample of y\n",
    "display(y)\n",
    "display(y.value_counts())\n",
    "# Observed target variable, y, is already numerically encoded, therefore can forgo encoding via something like LabelEncoder() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0           1      5000                   1.0                   0.0   \n",
       "1           1    108590                   0.0                   0.0   \n",
       "2           1      5000                   0.0                   0.0   \n",
       "3           1      6692                   0.0                   0.0   \n",
       "4           1    142590                   0.0                   0.0   \n",
       "...       ...       ...                   ...                   ...   \n",
       "34294       1      5000                   0.0                   0.0   \n",
       "34295       1      5000                   0.0                   0.0   \n",
       "34296       1      5000                   0.0                   0.0   \n",
       "34297       1      5000                   0.0                   0.0   \n",
       "34298       1  36500179                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                   0.0                   0.0                   0.0   \n",
       "34295                   0.0                   0.0                   0.0   \n",
       "34296                   0.0                   0.0                   0.0   \n",
       "34297                   0.0                   0.0                   0.0   \n",
       "34298                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  ...  \\\n",
       "0                       0.0                   0.0                  0.0  ...   \n",
       "1                       0.0                   0.0                  0.0  ...   \n",
       "2                       0.0                   0.0                  0.0  ...   \n",
       "3                       0.0                   0.0                  0.0  ...   \n",
       "4                       0.0                   0.0                  0.0  ...   \n",
       "...                     ...                   ...                  ...  ...   \n",
       "34294                   0.0                   0.0                  0.0  ...   \n",
       "34295                   0.0                   0.0                  0.0  ...   \n",
       "34296                   0.0                   0.0                  0.0  ...   \n",
       "34297                   0.0                   0.0                  0.0  ...   \n",
       "34298                   0.0                   0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    1.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     1.0                       0.0   \n",
       "4                    0.0                     0.0                       1.0   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                0.0                     0.0                       0.0   \n",
       "34295                0.0                     0.0                       0.0   \n",
       "34296                0.0                     0.0                       0.0   \n",
       "34297                0.0                     0.0                       0.0   \n",
       "34298                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                 0.0               0.0                     0.0   \n",
       "34295                 0.0               0.0                     0.0   \n",
       "34296                 0.0               0.0                     0.0   \n",
       "34297                 0.0               0.0                     0.0   \n",
       "34298                 0.0               1.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "...                ...                ...                       ...   \n",
       "34294              0.0                0.0                       1.0   \n",
       "34295              0.0                0.0                       1.0   \n",
       "34296              0.0                0.0                       1.0   \n",
       "34297              0.0                0.0                       1.0   \n",
       "34298              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "34294                       0.0  \n",
       "34295                       0.0  \n",
       "34296                       0.0  \n",
       "34297                       0.0  \n",
       "34298                       0.0  \n",
       "\n",
       "[34299 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
    "X = applicant_encoded_df.drop(columns=y_target)\n",
    "\n",
    "# Review the features DataFrame\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Split the features and target sets into training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Use scikit-learn's `StandardScaler` to scale the features data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler_fit = standard_scaler.fit(X_train)\n",
    "\n",
    "# Use the fit scaler to transform the scale of the features training and testing datasets\n",
    "X_train_scaled = X_scaler_fit.transform(X_train)\n",
    "X_test_scaled = X_scaler_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compile and Evaluate a Binary Classification Model Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers. 'relu' is the Rectified Linear Unit activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25724, 116)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = X_train.shape[1] # Alternative formulation is: len(X_train.iloc[0])\n",
    "#print(X_train_scaled.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Review the number of features\n",
    "print(number_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1 # Single target variable output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "# We will use the general guidance provided in class, although this is more art than recipe:\n",
    "# Use the mean of the number of input features plus the number of output neurons\n",
    "hidden_nodes_layer_1 = (number_input_features + number_output_neurons) // 2 # Python floor division operator (//) returns the quotient rounded down to the nearest integer\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n",
    "print(hidden_nodes_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "# We will use the general guidance provided in class, although more art than recipe:\n",
    "# Use the mean of the number of hidden nodes in the first hidden layer plus the number of output neurons\n",
    "hidden_nodes_layer_2 =  (hidden_nodes_layer_1 + number_output_neurons) // 2\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "print(hidden_nodes_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "neural_net = Sequential(name='neural_net_venture_funding_model') # An alternative formulation is the Functional Model, or Model() object, also from the Keras library (c.f. https://becominghuman.ai/sequential-vs-functional-model-in-keras-20684f766057)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "neural_net.add(Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, \n",
    "                                                      activation='relu', name='layer_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "neural_net.add(Dense(units=hidden_nodes_layer_2, activation='relu', name='layer_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "neural_net.add(Dense(units=number_output_neurons, activation='relu', name='layer_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.core.dense.Dense at 0x2dcdc15a0>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2dcdc1c90>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2dcdc1300>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer_1/kernel:0' shape=(116, 58) dtype=float32, numpy=\n",
       " array([[-0.08873172,  0.15002848, -0.17099756, ...,  0.01626182,\n",
       "          0.01158209, -0.07924043],\n",
       "        [ 0.10286887, -0.13420528, -0.17491573, ..., -0.00879359,\n",
       "         -0.09414656,  0.18028878],\n",
       "        [ 0.04036567,  0.10040961, -0.08102893, ..., -0.13573124,\n",
       "          0.01411664,  0.17424963],\n",
       "        ...,\n",
       "        [-0.02178933, -0.07411443,  0.17890383, ..., -0.03831896,\n",
       "          0.15701695, -0.06200225],\n",
       "        [ 0.04138559, -0.14657822,  0.03124471, ...,  0.06295647,\n",
       "          0.05822571,  0.16914017],\n",
       "        [ 0.0124885 , -0.1624426 ,  0.15294652, ...,  0.02395739,\n",
       "         -0.01650356,  0.0005907 ]], dtype=float32)>,\n",
       " <tf.Variable 'layer_1/bias:0' shape=(58,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_2/kernel:0' shape=(58, 29) dtype=float32, numpy=\n",
       " array([[-0.11791497, -0.21524099, -0.13010943, ...,  0.24708009,\n",
       "          0.10418165, -0.22583854],\n",
       "        [ 0.03353149, -0.17236687,  0.2420469 , ..., -0.02279551,\n",
       "         -0.08752865, -0.18490133],\n",
       "        [-0.24698323,  0.08698282, -0.00170892, ...,  0.04383972,\n",
       "         -0.04533951, -0.23888057],\n",
       "        ...,\n",
       "        [ 0.00803778, -0.08466792,  0.20861736, ...,  0.07262805,\n",
       "         -0.04119949,  0.04855651],\n",
       "        [-0.01282176, -0.02425292, -0.23558888, ...,  0.04770982,\n",
       "          0.14749685, -0.21042909],\n",
       "        [-0.08266559,  0.15195706, -0.15789579, ..., -0.14500521,\n",
       "         -0.10640247,  0.08287692]], dtype=float32)>,\n",
       " <tf.Variable 'layer_2/bias:0' shape=(29,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_out/kernel:0' shape=(29, 1) dtype=float32, numpy=\n",
       " array([[ 0.01985082],\n",
       "        [ 0.18901676],\n",
       "        [ 0.4076389 ],\n",
       "        [ 0.13881701],\n",
       "        [ 0.13261044],\n",
       "        [-0.43294334],\n",
       "        [ 0.13002568],\n",
       "        [-0.09136561],\n",
       "        [-0.3647411 ],\n",
       "        [-0.3264264 ],\n",
       "        [-0.43845752],\n",
       "        [-0.28469905],\n",
       "        [ 0.30257875],\n",
       "        [ 0.16743201],\n",
       "        [-0.39692062],\n",
       "        [-0.20171817],\n",
       "        [-0.35811386],\n",
       "        [ 0.06591105],\n",
       "        [-0.40601578],\n",
       "        [-0.27062893],\n",
       "        [ 0.27572024],\n",
       "        [ 0.4163925 ],\n",
       "        [-0.2503901 ],\n",
       "        [-0.19353116],\n",
       "        [-0.39703867],\n",
       "        [-0.3270529 ],\n",
       "        [-0.00191358],\n",
       "        [ 0.41667724],\n",
       "        [-0.20186605]], dtype=float32)>,\n",
       " <tf.Variable 'layer_out/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the model layers created, along with initial iterative input weights prior to seeing any data\n",
    "display(neural_net.layers)\n",
    "display(neural_net.weights) # For example, confirms 29 weights, corresponding to 29 nodes, applied to input at the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_net_venture_funding_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_1 (Dense)             (None, 58)                6786      \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 29)                1711      \n",
      "                                                                 \n",
      " layer_out (Dense)           (None, 1)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8527 (33.31 KB)\n",
      "Trainable params: 8527 (33.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the summary for the Sequential model build.\n",
    "# \"Every layer has both an input and output attribute,\" c.f. https://keras.io/guides/sequential_model/\n",
    "display(neural_net.summary())\n",
    "# For example, layer_1 has 6786 parameters for weights and bias = 116 features * 58 nodes + 58 bias parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model, specifying the training configuration, including the loss function, optimizer, and evaluation metric(s)\n",
    "# Available Keras optimizers: SGD, RMSprop, Adam, AdamW, Adadelta, Adagrad, Adamax, Adafactor, Nadam, Ftrl, c.f. https://keras.io/api/optimizers/\n",
    "# Available probabilistic loss functions for classification problems: binary_crossentropy, categorical_crossentropy, poisson, kl_divergence, c.f. https://keras.io/api/losses/\n",
    "# binary_crossentropy \"computes the cross-entropy loss between true labels and predicted labels.\" \\n\n",
    "# \"Use this cross-entropy loss for binary (0 or 1) classification applications.\" c.f. https://keras.io/api/losses/probabilistic_losses/#binary_crossentropy-function\n",
    "# Available metrics at https://keras.io/api/metrics/\n",
    "neural_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/804 [..............................] - ETA: 4:09 - loss: 7.2068 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 01:40:00.536882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 5s 6ms/step - loss: 2.4122 - accuracy: 0.6371\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.4169 - accuracy: 0.6618\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.3724 - accuracy: 0.6618\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 3.1830 - accuracy: 0.6357\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 5.8370 - accuracy: 0.5740\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 5s 7ms/step - loss: 5.0325 - accuracy: 0.6299\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.6565 - accuracy: 0.6342\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.2990 - accuracy: 0.6549\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 3.8298 - accuracy: 0.7017\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 3.8694 - accuracy: 0.7048\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 3.9558 - accuracy: 0.7062\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.2185 - accuracy: 0.7008\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.3365 - accuracy: 0.6992\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.4009 - accuracy: 0.6960\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.4128 - accuracy: 0.7037\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.6165 - accuracy: 0.6936\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.4880 - accuracy: 0.7031\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.3662 - accuracy: 0.7029\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.2085 - accuracy: 0.7087\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1397 - accuracy: 0.7221\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.2332 - accuracy: 0.7193\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5267 - accuracy: 0.6971\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5425 - accuracy: 0.6940\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1512 - accuracy: 0.7169\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1542 - accuracy: 0.7174\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1647 - accuracy: 0.7168\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1576 - accuracy: 0.7174\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1398 - accuracy: 0.7201\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.1684 - accuracy: 0.7090\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.0984 - accuracy: 0.6941\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.4481 - accuracy: 0.7000\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.3608 - accuracy: 0.7051\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.8260 - accuracy: 0.6781\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 5.9600 - accuracy: 0.6094\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 5.4994 - accuracy: 0.6343\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 5.9973 - accuracy: 0.6046\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 5.2034 - accuracy: 0.6567\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5071 - accuracy: 0.7061\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 4.5073 - accuracy: 0.7062\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "neural_net_trained_model = neural_net.fit(X_train_scaled, y_train, epochs=50)\n",
    "# 32 training samples is the default batch size.  The total training sample size is 25724, or 75% of 34299. \\n\n",
    "# Therefore, there are 804 batches run per epoch, at 32 samples per batch, equals 25724 training samples per epoch.\n",
    "# The model struggles in training to reduce losses, while little progress is made to improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 4.4750 - accuracy: 0.7082 - 776ms/epoch - 3ms/step\n",
      "Loss: 4.475027561187744, Accuracy: 0.7082215547561646\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = neural_net.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bozmbp18/Tresorit/Boz & Company LLC/IAR/Todd Meier/Education/Columbia Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_13/Homework/neural-networks-challenge/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Set the model's file path\n",
    "file_nm_path = Path('Resources/AlphabetSoup.h5')\n",
    "# Alternatively, set the file name path to the native .keras file format\n",
    "file_nm_path_alt = Path('Resources/AlphabetSoup.keras')\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "neural_net.save(file_nm_path)\n",
    "# Alternatively, export to the native .keras file format\n",
    "neural_net.save(file_nm_path_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimize the neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define at least three new deep neural network models (resulting in the original plus 2 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`A priori neural net venture funding model optimizing strategy:`**\n",
    "\n",
    "`Will take incremental optimizing approach to assess impact of marginal changes to model, while holding everything else constant.`\n",
    ">1. `Alternative model A1: Modify the activation function uniformly across all layers to \"LeakyReLU\" from the base model's \"ReLU\" and assess change in the model's performance and accuracy.`  \n",
    ">2. `Alternative model A2: Maintain the activation function as \"LeakyReLU\" across all layers, except the output layer where the activation function is modified to the binary-focused 'Sigmoid'.`\n",
    ">3. `Alternative model A3: Condense the model from 2 hidden layers to 1 hidden layer, or a shallower model.  Maintain 'LeakyReLU' on the hidden layer and the 'Sigmoid' activation function on the output layer, based on the results of our previous testing. Increase the number of nodes on the hidden layer, from the original formulation using the mean of the features and output, to a rule-of-thumb multiple of 2 to 3 times the features (course instructor's guidance), selecting a conservative 3 times multiple.`\n",
    "\n",
    "`Following training and evaluation of our A3 model, we reviewed the original dataset's (applicant_data_df) nine features to assess whether a feature or features might be confusing or unnecessarily complicating the venture fund model, and should therefore be excluded as explanatory variable(s) from our model.  We did not see any suspect column that should be excluded, except perhaps the 'Special_Considerations' feature, which wasn't well understood by us and perhaps not by our venture capital firm where the field could be liberally or ambiguously interpreted by associates maintaining the dataset, leading to an unnecessary and inconsistent bifurcation within the dataset.  Given our limited resources and the three alternative models already investigated and developed, we will defer this question to a later time, junior associate or consultant.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Model 1:\n",
    "* `Alternative model A1: Modify the activation function uniformly across all layers to 'LeakyReLU' from the base 'ReLU', and assess change in model's performance and accuracy.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features_A1 = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A1 = 1 # Maintain single target variable output neuron\n",
    "number_output_neurons_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A1 = (number_input_features_A1 + number_output_neurons_A1) // 2 # Maintain first layer number of nodes\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A1 = (hidden_nodes_layer1_A1 + number_output_neurons_A1) // 2 # Maintain second layer number of nodes\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer2_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LeakyReLU, which is available as a layer, not as an activation function per se.\n",
    "# LeakyReLU is considered an \"advanced activation\" layer.\n",
    "# \"Activations that are more complex than a simple TensorFlow function (eg. learnable activations, which maintain a state) are available as Advanced Activation layers, \\n\n",
    "# and can be found in the module tf.keras.layers.advanced_activations. These include PReLU and LeakyReLU. Note that you should not pass activation layers instances as \\n\n",
    "# the activation argument of a layer. They're meant to be used just like regular layers,\" c.f. https://keras.io/api/layers/activations/\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Create the Sequential model instance\n",
    "neural_net_A1 = Sequential(name='neural_net_venture_funding_model_A1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_net_venture_funding_model_A1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_1a_A1 (Dense)         (None, 58)                6786      \n",
      "                                                                 \n",
      " layer_1b_A1 (LeakyReLU)     (None, 58)                0         \n",
      "                                                                 \n",
      " layer_2a_A1 (Dense)         (None, 29)                1711      \n",
      "                                                                 \n",
      " layer_2b_A1 (LeakyReLU)     (None, 29)                0         \n",
      "                                                                 \n",
      " layer_out_a_A1 (Dense)      (None, 1)                 30        \n",
      "                                                                 \n",
      " layer_out_b_A1 (LeakyReLU)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8527 (33.31 KB)\n",
      "Trainable params: 8527 (33.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add layers to the neural_net instance\n",
    "\n",
    "# First hidden layer ('1a' and '1b')\n",
    "# 2-Step process since there is no alias for LeakyReLU as there is for ReLU 'relu':\n",
    "# First step: Applies weights to inputs and adds bias\n",
    "neural_net_A1.add(Dense(\n",
    "    units=hidden_nodes_layer1_A1, input_dim=number_input_features_A1, name='layer_1a_A1'))\n",
    "# Second step: \n",
    "neural_net_A1.add(LeakyReLU(name='layer_1b_A1')) # alpha parameter default for LeakyReLU is 0.3, assume for all LeakyReLU layers for now\n",
    "\n",
    "# Second hidden layer ('2a' and '2b')\n",
    "neural_net_A1.add(Dense(units=hidden_nodes_layer2_A1, name='layer_2a_A1'))\n",
    "neural_net_A1.add(LeakyReLU(name='layer_2b_A1'))\n",
    "\n",
    "# Output layer ('out_a' and 'out_b')\n",
    "neural_net_A1.add(Dense(units=number_output_neurons_A1, name='layer_out_a_A1'))\n",
    "neural_net_A1.add(LeakyReLU(name='layer_out_b_A1'))\n",
    "\n",
    "# Check the structure of the model\n",
    "display(neural_net_A1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer_1a_A1/kernel:0' shape=(116, 58) dtype=float32, numpy=\n",
       " array([[ 0.09147923,  0.11638416, -0.00267804, ...,  0.05232108,\n",
       "         -0.08752505,  0.12196316],\n",
       "        [-0.00876327, -0.00890462,  0.14985596, ...,  0.03014059,\n",
       "         -0.0530757 ,  0.16514863],\n",
       "        [ 0.06897564,  0.10077347,  0.12573908, ..., -0.08376962,\n",
       "          0.16042583, -0.14160709],\n",
       "        ...,\n",
       "        [-0.10672785,  0.08688669, -0.06062394, ...,  0.01372661,\n",
       "         -0.10027432, -0.17325912],\n",
       "        [ 0.12673666,  0.08554931, -0.1717792 , ..., -0.02993524,\n",
       "          0.04285811, -0.05640572],\n",
       "        [ 0.09260859,  0.15380265, -0.14094901, ...,  0.03624701,\n",
       "         -0.02030972,  0.12925027]], dtype=float32)>,\n",
       " <tf.Variable 'layer_1a_A1/bias:0' shape=(58,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_2a_A1/kernel:0' shape=(58, 29) dtype=float32, numpy=\n",
       " array([[-0.18205541,  0.16101998,  0.17559859, ...,  0.07421112,\n",
       "         -0.00926629, -0.22915903],\n",
       "        [-0.09011258,  0.05355138,  0.17907849, ..., -0.13332205,\n",
       "          0.2045283 , -0.05624598],\n",
       "        [ 0.21716285, -0.17979419,  0.16352955, ...,  0.00686857,\n",
       "         -0.18797731, -0.06985028],\n",
       "        ...,\n",
       "        [-0.05986245, -0.2047778 ,  0.20756477, ..., -0.03136112,\n",
       "          0.01771489, -0.10676643],\n",
       "        [ 0.18618849, -0.18186684,  0.20328978, ...,  0.00177616,\n",
       "          0.19328198, -0.11699758],\n",
       "        [-0.01501851,  0.14638963,  0.06969067, ..., -0.06443454,\n",
       "         -0.04372883,  0.06908911]], dtype=float32)>,\n",
       " <tf.Variable 'layer_2a_A1/bias:0' shape=(29,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_a_A1/kernel:0' shape=(29, 1) dtype=float32, numpy=\n",
       " array([[ 0.02982509],\n",
       "        [-0.00881481],\n",
       "        [ 0.4336958 ],\n",
       "        [-0.35280517],\n",
       "        [-0.19914255],\n",
       "        [-0.3268632 ],\n",
       "        [-0.3277112 ],\n",
       "        [-0.27210528],\n",
       "        [ 0.37253582],\n",
       "        [-0.41900536],\n",
       "        [-0.19115418],\n",
       "        [-0.11524084],\n",
       "        [ 0.1861341 ],\n",
       "        [ 0.14279455],\n",
       "        [ 0.2524116 ],\n",
       "        [-0.23638846],\n",
       "        [-0.39778665],\n",
       "        [-0.08666101],\n",
       "        [-0.00159073],\n",
       "        [-0.33917275],\n",
       "        [ 0.25237894],\n",
       "        [ 0.09050781],\n",
       "        [ 0.3511095 ],\n",
       "        [-0.30788636],\n",
       "        [ 0.15651864],\n",
       "        [ 0.10162497],\n",
       "        [-0.22584142],\n",
       "        [ 0.08740443],\n",
       "        [-0.14318061]], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_a_A1/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the model's dense layers created, along with initial iterative input weights and bias prior to seeing any data\n",
    "display(neural_net_A1.weights)\n",
    "#weights, biases = neural_net_A1.layers[0].get_weights()\n",
    "#print(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "neural_net_A1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/804 [..............................] - ETA: 4:10 - loss: 6.2601 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 01:45:10.100257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 5s 6ms/step - loss: 2.3203 - accuracy: 0.5958\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.3251 - accuracy: 0.6336\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 6s 7ms/step - loss: 2.3154 - accuracy: 0.6451\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9524 - accuracy: 0.6561\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.0362 - accuracy: 0.6754\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9759 - accuracy: 0.6827\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 5s 7ms/step - loss: 2.0155 - accuracy: 0.6837\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.0374 - accuracy: 0.6852\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 2.0378 - accuracy: 0.6783\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9278 - accuracy: 0.6740\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9561 - accuracy: 0.6710\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.7758 - accuracy: 0.6853\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9755 - accuracy: 0.6677\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9593 - accuracy: 0.6872\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9808 - accuracy: 0.6857\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9738 - accuracy: 0.6882\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.9659 - accuracy: 0.6899\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.8419 - accuracy: 0.6834\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 1.1921 - accuracy: 0.7056\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.9046 - accuracy: 0.7175\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.8369 - accuracy: 0.7196\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.8533 - accuracy: 0.7178\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.8111 - accuracy: 0.7236\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7920 - accuracy: 0.7255\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7651 - accuracy: 0.7257\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7566 - accuracy: 0.7206\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.8056 - accuracy: 0.7197\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7779 - accuracy: 0.7275\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7641 - accuracy: 0.7241\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7402 - accuracy: 0.7244\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7165 - accuracy: 0.7236\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7018 - accuracy: 0.7262\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6878 - accuracy: 0.7287\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6852 - accuracy: 0.7303\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.7179 - accuracy: 0.7076\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6468 - accuracy: 0.7227\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6946 - accuracy: 0.7034\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6472 - accuracy: 0.7281\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 5s 7ms/step - loss: 0.6296 - accuracy: 0.7283\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6748 - accuracy: 0.7269\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6659 - accuracy: 0.7286\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6722 - accuracy: 0.7177\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6375 - accuracy: 0.7297\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6499 - accuracy: 0.7285\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6391 - accuracy: 0.7305\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6442 - accuracy: 0.7234\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6361 - accuracy: 0.7291\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6289 - accuracy: 0.7299\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6258 - accuracy: 0.7209\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.6160 - accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "neural_net_trained_model_A1 = neural_net_A1.fit(X_train_scaled, y_train, epochs=50)\n",
    "# We observed that the LeakyReLU activation function produced an immediate improvement in reducing the loss and increasing the accuracy at the very outset of training, in the first few epochs.\n",
    "# However, as with ReLU, we observed that the model with LeakyReLU struggled to marginally reduce loss and increase accuracy as training progressed.  While the LeakyReLU loss function plateaued \\n\n",
    "# around 0.7, significantly less than ReLU which plateaued around 4.2, after 50 epochs, LeakyReLU accuracy terminated at 0.73, not significantly superior to the ReLU model where accuracy terminated at 0.72.\n",
    "# While we demonstrated that LeakyReLU is the superior activation function in terms of both training efficiency, the speed at which the model converged on a solution, and fit, reflected in the loss \\n\n",
    "# function metric, the lack of improvement in accuracy indicates that we have more work to do to improve the model's predictive power as measured by accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Model 2:\n",
    "* `Alternative model A2: Maintain the activation function from the previous model, A1, across all layers as 'LeakyReLU', except the output layer where the activation function is changed to 'Sigmoid'.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features_A2 = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A2 = 1 # Maintain single target variable output neuron\n",
    "number_output_neurons_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A2 = (number_input_features_A2 + number_output_neurons_A2) // 2 # Maintain first layer number of nodes\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A2 = (hidden_nodes_layer1_A2 + number_output_neurons_A2) // 2 # Maintain second layer number of nodes\n",
    "\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LeakyReLU, which is available as a layer, not as an activation function per se.\n",
    "# LeakyReLU is considered an \"advanced activation\" layer.\n",
    "# \"Activations that are more complex than a simple TensorFlow function (eg. learnable activations, which maintain a state) are available as Advanced Activation layers, \\n\n",
    "# and can be found in the module tf.keras.layers.advanced_activations. These include PReLU and LeakyReLU. Note that you should not pass activation layers instances as \\n\n",
    "# the activation argument of a layer. They're meant to be used just like regular layers,\" c.f. https://keras.io/api/layers/activations/\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Create the Sequential model instance\n",
    "neural_net_A2 = Sequential(name='neural_net_venture_funding_model_A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_net_venture_funding_model_A2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_1a_A2 (Dense)         (None, 58)                6786      \n",
      "                                                                 \n",
      " layer_1b_A2 (LeakyReLU)     (None, 58)                0         \n",
      "                                                                 \n",
      " layer_2a_A2 (Dense)         (None, 29)                1711      \n",
      "                                                                 \n",
      " layer_2b_A2 (LeakyReLU)     (None, 29)                0         \n",
      "                                                                 \n",
      " layer_out_A2 (Dense)        (None, 1)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8527 (33.31 KB)\n",
      "Trainable params: 8527 (33.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add layers to the neural_net instance\n",
    "\n",
    "# First hidden layer ('1a' and '1b')\n",
    "# 2-Step process since there is no alias for LeakyReLU as there is for ReLU 'relu':\n",
    "# First step: Applies weights to inputs and adds bias\n",
    "neural_net_A2.add(Dense(\n",
    "    units=hidden_nodes_layer1_A2, input_dim=number_input_features_A2, name='layer_1a_A2'))\n",
    "# Second step: \n",
    "neural_net_A2.add(LeakyReLU(name='layer_1b_A2')) # alpha parameter default for LeakyReLU is 0.3, assume for all LeakyReLU layers for now\n",
    "\n",
    "# Second hidden layer ('2a' and '2b')\n",
    "neural_net_A2.add(Dense(units=hidden_nodes_layer2_A2, name='layer_2a_A2'))\n",
    "neural_net_A2.add(LeakyReLU(name='layer_2b_A2'))\n",
    "\n",
    "# Output layer ('out')\n",
    "neural_net_A2.add(Dense(units=number_output_neurons_A2, activation='sigmoid', name='layer_out_A2'))\n",
    "\n",
    "# Check the structure of the model\n",
    "display(neural_net_A2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer_1a_A2/kernel:0' shape=(116, 58) dtype=float32, numpy=\n",
       " array([[-1.47447079e-01,  6.40165508e-02, -1.46042958e-01, ...,\n",
       "          1.29904792e-01,  1.02464780e-01,  1.46716833e-04],\n",
       "        [ 2.87679881e-02, -1.56906053e-01, -3.29940021e-02, ...,\n",
       "         -1.56082615e-01,  6.76776320e-02, -1.07625932e-01],\n",
       "        [ 7.20581263e-02,  3.14129591e-02, -5.97046912e-02, ...,\n",
       "         -1.06512859e-01, -3.92729491e-02, -1.71243623e-01],\n",
       "        ...,\n",
       "        [ 1.64926156e-01,  1.51992694e-01,  1.01527885e-01, ...,\n",
       "          5.80614954e-02,  5.17394990e-02,  4.18140143e-02],\n",
       "        [ 1.42589435e-01,  7.26232976e-02,  8.61750692e-02, ...,\n",
       "          1.54253259e-01, -1.77153841e-01,  2.15867758e-02],\n",
       "        [-7.45952129e-04, -6.74048662e-02,  1.71317950e-01, ...,\n",
       "          1.79496512e-01, -8.56673941e-02, -1.27675548e-01]], dtype=float32)>,\n",
       " <tf.Variable 'layer_1a_A2/bias:0' shape=(58,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_2a_A2/kernel:0' shape=(58, 29) dtype=float32, numpy=\n",
       " array([[ 0.20052633,  0.08574003,  0.17780188, ..., -0.01861116,\n",
       "          0.01752061, -0.14164779],\n",
       "        [ 0.23247713, -0.08088773, -0.1995819 , ..., -0.20518804,\n",
       "         -0.23912556,  0.22255355],\n",
       "        [ 0.05651316, -0.01725411,  0.18916664, ..., -0.0756098 ,\n",
       "         -0.09176466, -0.10718763],\n",
       "        ...,\n",
       "        [-0.2595295 ,  0.16332647,  0.07877716, ..., -0.03547089,\n",
       "          0.15430689,  0.01197112],\n",
       "        [-0.17036718, -0.11108927,  0.21287018, ...,  0.02800381,\n",
       "         -0.06181306,  0.05352086],\n",
       "        [-0.23577966, -0.12411679, -0.09653085, ...,  0.1549541 ,\n",
       "          0.03902543, -0.08202645]], dtype=float32)>,\n",
       " <tf.Variable 'layer_2a_A2/bias:0' shape=(29,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_A2/kernel:0' shape=(29, 1) dtype=float32, numpy=\n",
       " array([[ 0.43946493],\n",
       "        [ 0.07068312],\n",
       "        [-0.19078621],\n",
       "        [ 0.38280213],\n",
       "        [ 0.01016894],\n",
       "        [ 0.40758455],\n",
       "        [ 0.32991993],\n",
       "        [ 0.0945462 ],\n",
       "        [-0.20851278],\n",
       "        [ 0.12661153],\n",
       "        [-0.37965083],\n",
       "        [ 0.12134558],\n",
       "        [ 0.09877127],\n",
       "        [ 0.4346217 ],\n",
       "        [ 0.3083982 ],\n",
       "        [-0.08109334],\n",
       "        [ 0.15847254],\n",
       "        [ 0.25191474],\n",
       "        [-0.26884183],\n",
       "        [ 0.38886052],\n",
       "        [-0.42574772],\n",
       "        [ 0.41883218],\n",
       "        [ 0.01245987],\n",
       "        [-0.27768192],\n",
       "        [-0.00200027],\n",
       "        [ 0.17234641],\n",
       "        [ 0.08961332],\n",
       "        [-0.36608356],\n",
       "        [-0.20464212]], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_A2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the model's dense layers created, along with initial iterative input weights and bias prior to seeing any data\n",
    "display(neural_net_A2.weights)\n",
    "#weights, biases = neural_net_A2.layers[0].get_weights()\n",
    "#print(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "neural_net_A2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/804 [..............................] - ETA: 4:14 - loss: 0.8823 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 01:52:34.123024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5854 - accuracy: 0.7196\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5572 - accuracy: 0.7282\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5539 - accuracy: 0.7298\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5508 - accuracy: 0.7285\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5503 - accuracy: 0.7296\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5489 - accuracy: 0.7323\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5482 - accuracy: 0.7323\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5471 - accuracy: 0.7329\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5467 - accuracy: 0.7346\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5453 - accuracy: 0.7320\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5454 - accuracy: 0.7330\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5449 - accuracy: 0.7347\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5443 - accuracy: 0.7350\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5438 - accuracy: 0.7339\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5439 - accuracy: 0.7329\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5429 - accuracy: 0.7328\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5427 - accuracy: 0.7334\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5422 - accuracy: 0.7336\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5419 - accuracy: 0.7335\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5423 - accuracy: 0.7343\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5416 - accuracy: 0.7350\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5417 - accuracy: 0.7358\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5410 - accuracy: 0.7348\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5414 - accuracy: 0.7353\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5411 - accuracy: 0.7338\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5405 - accuracy: 0.7348\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5404 - accuracy: 0.7346\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5403 - accuracy: 0.7367\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5397 - accuracy: 0.7369\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5399 - accuracy: 0.7349\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5396 - accuracy: 0.7354\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5397 - accuracy: 0.7361\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5394 - accuracy: 0.7363\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5388 - accuracy: 0.7384\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5393 - accuracy: 0.7363\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5388 - accuracy: 0.7374\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5385 - accuracy: 0.7364\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5390 - accuracy: 0.7359\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5388 - accuracy: 0.7362\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5389 - accuracy: 0.7358\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5389 - accuracy: 0.7369\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5383 - accuracy: 0.7362\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5384 - accuracy: 0.7362\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5379 - accuracy: 0.7377\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5386 - accuracy: 0.7365\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5379 - accuracy: 0.7378\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5382 - accuracy: 0.7366\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5371 - accuracy: 0.7371\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5376 - accuracy: 0.7364\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "neural_net_trained_model_A2 = neural_net_A2.fit(X_train_scaled, y_train, epochs=50)\n",
    "# Prior to running the training, we did not know what to expect by only changing the activation function of a single layer, the output layer, from LeakyReLU to Sigmoid.  We wanted to test the change to Sigmoid because we have a binary classification problem, defined as having two labels, and we knew the Sigmoid activation function is designed to separate data between probabilities of 0 and 1 with most of the data pushed toward either extreme, 0 or 1, characteristic of the sigmoid transform shape.\n",
    "\n",
    "# We also noted the following attractive characteristics discussed by Sharma, which surprisingly confirmed our suspicion to use the Sigmoid activation in the output layer, if anywhere:\n",
    "#\n",
    "#   1) The sigmoid activation function is both non-linear and differentiable which are good characteristics for activation function.\n",
    "#   2) As its output ranges between 0 to 1, it can be used in the output layer to produce the result in probability for binary classification.\n",
    "#   3) When the input values are too small or too high, it can cause the neural network to stop learning, this issue is known as the vanishing gradient problem. This is why the Sigmoid activation function should #       not be used in hidden layers.\n",
    "# c.f. Sharma, https://machinelearningknowledge.ai/pytorch-activation-functions-relu-leaky-relu-sigmoid-tanh-and-softmax/\n",
    "\n",
    "# We were quite surprised to see an immediate benefit to the model in training where the loss function started at a materially lower loss and an accuracy that already nearly matched the final epochs in the A1 training.  We also noted the more well behaved training behavior over the entire span of epochs, where loss improvement, while slow, was steady with few reversals, and none large, and accuracy slightly improved over the span along a similar steady line.  While the loss and accuracy started out much improved, and the A2 model maintained its superiority over the original and A1 models to the end of training, we did not that the improvement over time was slow and modest, consistent with the remarks above noting the Sigmoid's tendency to experience a reduced gradient force driving potential further improvement.\n",
    "\n",
    "# As a result of this training, we considered testing an A3 model by replacing not only the output layer activation function with Sigmoid, but also the two hidden layers with the Sigmoid activation function.\n",
    "# However, we suspect this might not be useful, that the real import of the Sigmoid activation function is at the output layer, and will take Sharma's advice not to introduce the Sigmoid activation function in the hidden layers, although we don't really know the effect without attempting, which we may do at a later time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Model 3\n",
    "* `Alternative model A3: Condense the model from 2 hidden layers to 1 hidden layer, or a shallower model.  Maintain 'LeakyReLU' on the hidden layer and the 'Sigmoid' activation function on the output layer, based on the results of our previous testing. Increase the number of nodes on the hidden layer, from the original formulation using the mean of the features and output, to a rule-of-thumb multiple of 2 to 3 times the features, selecting a conservative 3 times multiple.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features_A3 = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features_A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A3 = 1 # Maintain single target variable output neuron\n",
    "number_output_neurons_A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "node_multiplier_layer1_A3 = 3\n",
    "hidden_nodes_layer1_A3 = (number_input_features_A3 * node_multiplier_layer1_A3)\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LeakyReLU, which is available as a layer, not as an activation function per se.\n",
    "# LeakyReLU is considered an \"advanced activation\" layer.\n",
    "# \"Activations that are more complex than a simple TensorFlow function (eg. learnable activations, which maintain a state) are available as Advanced Activation layers, \\n\n",
    "# and can be found in the module tf.keras.layers.advanced_activations. These include PReLU and LeakyReLU. Note that you should not pass activation layers instances as \\n\n",
    "# the activation argument of a layer. They're meant to be used just like regular layers,\" c.f. https://keras.io/api/layers/activations/\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Create the Sequential model instance\n",
    "neural_net_A3 = Sequential(name='neural_net_venture_funding_model_A3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_net_venture_funding_model_A3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_1a_A3 (Dense)         (None, 348)               40716     \n",
      "                                                                 \n",
      " layer_1b_A3 (LeakyReLU)     (None, 348)               0         \n",
      "                                                                 \n",
      " layer_out_A3 (Dense)        (None, 1)                 349       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41065 (160.41 KB)\n",
      "Trainable params: 41065 (160.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add layers to the neural_net instance\n",
    "\n",
    "# First hidden layer ('1a' and '1b')\n",
    "# 2-Step process since there is no alias for LeakyReLU as there is for ReLU 'relu':\n",
    "# First step: Applies weights to inputs and adds bias\n",
    "neural_net_A3.add(Dense(\n",
    "    units=hidden_nodes_layer1_A3, input_dim=number_input_features_A3, name='layer_1a_A3'))\n",
    "# Second step: \n",
    "neural_net_A3.add(LeakyReLU(name='layer_1b_A3')) # alpha parameter default for LeakyReLU is 0.3, assume for all LeakyReLU layers for now\n",
    "\n",
    "# Output layer ('out')\n",
    "neural_net_A3.add(Dense(units=number_output_neurons_A3, activation='sigmoid', name='layer_out_A3'))\n",
    "\n",
    "# Check the structure of the model\n",
    "display(neural_net_A3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer_1a_A3/kernel:0' shape=(116, 348) dtype=float32, numpy=\n",
       " array([[ 0.08234495, -0.07943785,  0.00072068, ..., -0.08382428,\n",
       "         -0.04840802,  0.08248797],\n",
       "        [ 0.01409575,  0.04724495,  0.08510229, ...,  0.10710184,\n",
       "         -0.0772088 ,  0.06473574],\n",
       "        [-0.03503314,  0.06825931, -0.070598  , ..., -0.05019045,\n",
       "         -0.08354166, -0.0109862 ],\n",
       "        ...,\n",
       "        [-0.10023233, -0.06052174, -0.10864536, ..., -0.07769787,\n",
       "          0.03044544, -0.0289284 ],\n",
       "        [ 0.05292003,  0.02189657, -0.08174283, ..., -0.08037041,\n",
       "          0.07185557, -0.06627493],\n",
       "        [ 0.07941914,  0.07802019,  0.03444569, ...,  0.09239082,\n",
       "          0.07767963, -0.1051845 ]], dtype=float32)>,\n",
       " <tf.Variable 'layer_1a_A3/bias:0' shape=(348,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_A3/kernel:0' shape=(348, 1) dtype=float32, numpy=\n",
       " array([[ 0.09266397],\n",
       "        [ 0.00601806],\n",
       "        [-0.04870353],\n",
       "        [ 0.07765257],\n",
       "        [ 0.07321925],\n",
       "        [-0.10969141],\n",
       "        [ 0.12584984],\n",
       "        [-0.07632666],\n",
       "        [ 0.11788495],\n",
       "        [ 0.09778579],\n",
       "        [-0.06904954],\n",
       "        [-0.10024358],\n",
       "        [-0.09979086],\n",
       "        [-0.09512179],\n",
       "        [ 0.01528169],\n",
       "        [ 0.03794871],\n",
       "        [-0.05190994],\n",
       "        [ 0.02469566],\n",
       "        [-0.0929378 ],\n",
       "        [ 0.07903662],\n",
       "        [-0.10778584],\n",
       "        [-0.09359462],\n",
       "        [-0.07135648],\n",
       "        [ 0.11765447],\n",
       "        [-0.08705713],\n",
       "        [-0.04936045],\n",
       "        [-0.07293779],\n",
       "        [ 0.07761064],\n",
       "        [-0.03060859],\n",
       "        [-0.1254906 ],\n",
       "        [-0.01722357],\n",
       "        [-0.04905737],\n",
       "        [-0.09898151],\n",
       "        [ 0.04362087],\n",
       "        [-0.03672621],\n",
       "        [-0.12929153],\n",
       "        [-0.10796549],\n",
       "        [ 0.11063705],\n",
       "        [ 0.06976286],\n",
       "        [ 0.09633374],\n",
       "        [ 0.12611356],\n",
       "        [ 0.02811222],\n",
       "        [ 0.00527701],\n",
       "        [ 0.04354762],\n",
       "        [-0.11389868],\n",
       "        [ 0.11249234],\n",
       "        [ 0.0588727 ],\n",
       "        [ 0.01254377],\n",
       "        [ 0.13105774],\n",
       "        [-0.04162794],\n",
       "        [-0.10812755],\n",
       "        [ 0.06589974],\n",
       "        [ 0.04240462],\n",
       "        [-0.02890684],\n",
       "        [ 0.08321393],\n",
       "        [-0.11818953],\n",
       "        [ 0.02144702],\n",
       "        [ 0.08983485],\n",
       "        [ 0.00347365],\n",
       "        [ 0.03732896],\n",
       "        [-0.03293047],\n",
       "        [ 0.05308601],\n",
       "        [ 0.11001134],\n",
       "        [-0.01987222],\n",
       "        [ 0.01362665],\n",
       "        [-0.06947237],\n",
       "        [-0.05387323],\n",
       "        [ 0.11619374],\n",
       "        [-0.06340027],\n",
       "        [ 0.07199395],\n",
       "        [-0.07879412],\n",
       "        [-0.0732473 ],\n",
       "        [-0.0184711 ],\n",
       "        [-0.1217792 ],\n",
       "        [-0.0118156 ],\n",
       "        [-0.00157405],\n",
       "        [-0.1229886 ],\n",
       "        [-0.09275523],\n",
       "        [ 0.01984808],\n",
       "        [-0.12047199],\n",
       "        [ 0.07655233],\n",
       "        [ 0.08203608],\n",
       "        [-0.02986351],\n",
       "        [ 0.10805736],\n",
       "        [ 0.02580315],\n",
       "        [-0.09744729],\n",
       "        [ 0.02032398],\n",
       "        [ 0.03544961],\n",
       "        [ 0.10743828],\n",
       "        [ 0.12213358],\n",
       "        [ 0.05818668],\n",
       "        [-0.09995274],\n",
       "        [-0.02598565],\n",
       "        [ 0.02483462],\n",
       "        [ 0.05226591],\n",
       "        [-0.0712788 ],\n",
       "        [-0.06206176],\n",
       "        [-0.11767088],\n",
       "        [ 0.08321902],\n",
       "        [-0.02359124],\n",
       "        [ 0.08680533],\n",
       "        [ 0.01741779],\n",
       "        [ 0.04808418],\n",
       "        [ 0.05891375],\n",
       "        [ 0.10323405],\n",
       "        [ 0.01253098],\n",
       "        [-0.09715991],\n",
       "        [-0.0005814 ],\n",
       "        [-0.07949819],\n",
       "        [ 0.0764062 ],\n",
       "        [ 0.03803331],\n",
       "        [ 0.08111009],\n",
       "        [-0.03617099],\n",
       "        [ 0.05490528],\n",
       "        [ 0.12055615],\n",
       "        [-0.04391125],\n",
       "        [-0.08532943],\n",
       "        [ 0.1248869 ],\n",
       "        [ 0.09333506],\n",
       "        [ 0.02239305],\n",
       "        [ 0.00761275],\n",
       "        [ 0.02098161],\n",
       "        [ 0.06676404],\n",
       "        [-0.05659606],\n",
       "        [-0.08838494],\n",
       "        [-0.03944755],\n",
       "        [-0.01491979],\n",
       "        [-0.12844752],\n",
       "        [-0.1183464 ],\n",
       "        [ 0.02081937],\n",
       "        [-0.00661202],\n",
       "        [-0.11601382],\n",
       "        [ 0.125162  ],\n",
       "        [-0.1286646 ],\n",
       "        [ 0.10092188],\n",
       "        [-0.1279859 ],\n",
       "        [-0.04607151],\n",
       "        [-0.01635966],\n",
       "        [ 0.10308221],\n",
       "        [-0.07069527],\n",
       "        [ 0.09206448],\n",
       "        [-0.01505602],\n",
       "        [ 0.03646688],\n",
       "        [-0.08459598],\n",
       "        [ 0.02017717],\n",
       "        [-0.11533187],\n",
       "        [ 0.05944832],\n",
       "        [ 0.01625495],\n",
       "        [-0.11558761],\n",
       "        [ 0.01828156],\n",
       "        [ 0.02035254],\n",
       "        [-0.02844364],\n",
       "        [-0.03030283],\n",
       "        [ 0.07460003],\n",
       "        [-0.10318137],\n",
       "        [-0.09490164],\n",
       "        [-0.12383386],\n",
       "        [-0.04698524],\n",
       "        [-0.07970479],\n",
       "        [ 0.0984211 ],\n",
       "        [-0.0951422 ],\n",
       "        [ 0.09739248],\n",
       "        [ 0.02765004],\n",
       "        [-0.05170234],\n",
       "        [-0.09025994],\n",
       "        [-0.00459599],\n",
       "        [-0.10755973],\n",
       "        [ 0.03026079],\n",
       "        [-0.06219675],\n",
       "        [-0.02804838],\n",
       "        [ 0.11448504],\n",
       "        [-0.10421798],\n",
       "        [-0.02262681],\n",
       "        [-0.00862104],\n",
       "        [ 0.13071123],\n",
       "        [ 0.10712001],\n",
       "        [-0.05212899],\n",
       "        [ 0.12187684],\n",
       "        [-0.08675756],\n",
       "        [ 0.05954947],\n",
       "        [ 0.08934215],\n",
       "        [-0.10900564],\n",
       "        [-0.11500034],\n",
       "        [-0.04302253],\n",
       "        [-0.08317023],\n",
       "        [ 0.11567231],\n",
       "        [-0.09620591],\n",
       "        [ 0.04452281],\n",
       "        [-0.06516836],\n",
       "        [ 0.11130579],\n",
       "        [ 0.05434974],\n",
       "        [ 0.04715876],\n",
       "        [ 0.10530162],\n",
       "        [ 0.10019851],\n",
       "        [ 0.11787896],\n",
       "        [-0.04553744],\n",
       "        [ 0.12155038],\n",
       "        [-0.02765271],\n",
       "        [-0.12927274],\n",
       "        [ 0.00681008],\n",
       "        [-0.07563229],\n",
       "        [ 0.01054503],\n",
       "        [-0.01936904],\n",
       "        [ 0.06341274],\n",
       "        [-0.08988703],\n",
       "        [ 0.1271351 ],\n",
       "        [ 0.06514813],\n",
       "        [-0.01734532],\n",
       "        [-0.01045449],\n",
       "        [-0.12143455],\n",
       "        [ 0.04440179],\n",
       "        [ 0.08171381],\n",
       "        [-0.05172581],\n",
       "        [-0.08846369],\n",
       "        [ 0.01638283],\n",
       "        [ 0.04645668],\n",
       "        [-0.01170378],\n",
       "        [ 0.05586906],\n",
       "        [ 0.12374198],\n",
       "        [ 0.02710967],\n",
       "        [-0.12111463],\n",
       "        [-0.1091309 ],\n",
       "        [ 0.08127381],\n",
       "        [ 0.03934567],\n",
       "        [-0.10106465],\n",
       "        [-0.06918359],\n",
       "        [ 0.10756104],\n",
       "        [ 0.04632378],\n",
       "        [ 0.04323576],\n",
       "        [ 0.10558625],\n",
       "        [-0.10967394],\n",
       "        [ 0.0815521 ],\n",
       "        [ 0.02073586],\n",
       "        [-0.1304827 ],\n",
       "        [-0.05698667],\n",
       "        [ 0.12598976],\n",
       "        [-0.02106492],\n",
       "        [ 0.00905615],\n",
       "        [-0.10522737],\n",
       "        [ 0.0980726 ],\n",
       "        [ 0.03195935],\n",
       "        [-0.09931332],\n",
       "        [-0.02279206],\n",
       "        [-0.07490179],\n",
       "        [ 0.10532565],\n",
       "        [ 0.03270398],\n",
       "        [-0.09651108],\n",
       "        [ 0.13074094],\n",
       "        [-0.00030017],\n",
       "        [ 0.02333619],\n",
       "        [-0.09068885],\n",
       "        [ 0.01057664],\n",
       "        [ 0.01835868],\n",
       "        [-0.09880814],\n",
       "        [-0.12746964],\n",
       "        [ 0.0211401 ],\n",
       "        [-0.05574188],\n",
       "        [ 0.0111101 ],\n",
       "        [ 0.08827375],\n",
       "        [-0.10263099],\n",
       "        [ 0.02057128],\n",
       "        [-0.09725569],\n",
       "        [ 0.00892505],\n",
       "        [-0.11507574],\n",
       "        [-0.11608351],\n",
       "        [-0.12742278],\n",
       "        [-0.11282843],\n",
       "        [-0.05612214],\n",
       "        [ 0.06280284],\n",
       "        [ 0.08677112],\n",
       "        [-0.01682045],\n",
       "        [-0.12377419],\n",
       "        [ 0.01435731],\n",
       "        [ 0.08618629],\n",
       "        [ 0.02089752],\n",
       "        [-0.06197339],\n",
       "        [ 0.0880594 ],\n",
       "        [ 0.11785732],\n",
       "        [-0.01173189],\n",
       "        [ 0.11837722],\n",
       "        [-0.0390567 ],\n",
       "        [ 0.05066943],\n",
       "        [ 0.10221447],\n",
       "        [ 0.02202079],\n",
       "        [ 0.00046319],\n",
       "        [ 0.02349256],\n",
       "        [-0.13108483],\n",
       "        [-0.12815244],\n",
       "        [ 0.0377707 ],\n",
       "        [ 0.01677547],\n",
       "        [-0.0566954 ],\n",
       "        [ 0.07173939],\n",
       "        [ 0.09313962],\n",
       "        [-0.01815827],\n",
       "        [ 0.01543915],\n",
       "        [-0.03992162],\n",
       "        [ 0.06829277],\n",
       "        [ 0.02099936],\n",
       "        [-0.03842612],\n",
       "        [-0.00940372],\n",
       "        [ 0.11613418],\n",
       "        [ 0.12004396],\n",
       "        [-0.00053525],\n",
       "        [ 0.01729025],\n",
       "        [-0.0515705 ],\n",
       "        [-0.03066821],\n",
       "        [ 0.07509083],\n",
       "        [ 0.00660305],\n",
       "        [ 0.06350112],\n",
       "        [-0.11152671],\n",
       "        [-0.09706984],\n",
       "        [-0.08557817],\n",
       "        [ 0.11010315],\n",
       "        [-0.06930432],\n",
       "        [ 0.01851431],\n",
       "        [-0.08751322],\n",
       "        [-0.03322345],\n",
       "        [ 0.05265939],\n",
       "        [-0.08303006],\n",
       "        [-0.00633161],\n",
       "        [ 0.12827015],\n",
       "        [-0.06582768],\n",
       "        [ 0.01373728],\n",
       "        [-0.04497315],\n",
       "        [ 0.12719008],\n",
       "        [ 0.01543981],\n",
       "        [ 0.05836342],\n",
       "        [ 0.08556291],\n",
       "        [-0.11297479],\n",
       "        [ 0.01218697],\n",
       "        [ 0.09297444],\n",
       "        [ 0.07932559],\n",
       "        [ 0.00895694],\n",
       "        [-0.07209218],\n",
       "        [-0.07677129],\n",
       "        [-0.06598914],\n",
       "        [-0.01481788],\n",
       "        [ 0.09432606],\n",
       "        [ 0.02719304],\n",
       "        [ 0.11217001],\n",
       "        [-0.02895288],\n",
       "        [-0.09140316],\n",
       "        [ 0.08569887],\n",
       "        [ 0.00640279],\n",
       "        [ 0.12080082],\n",
       "        [-0.08779401],\n",
       "        [ 0.05346893],\n",
       "        [ 0.06563018]], dtype=float32)>,\n",
       " <tf.Variable 'layer_out_A3/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the model's dense layers created, along with initial iterative input weights and bias prior to seeing any data\n",
    "display(neural_net_A3.weights)\n",
    "#weights, biases = neural_net_A3.layers[0].get_weights()\n",
    "#print(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "neural_net_A3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/804 [..............................] - ETA: 3:52 - loss: 0.7239 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 01:56:31.352811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 5s 5ms/step - loss: 0.5906 - accuracy: 0.7198\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5698 - accuracy: 0.7247\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5618 - accuracy: 0.7269\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5597 - accuracy: 0.7283\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5584 - accuracy: 0.7288\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5568 - accuracy: 0.7285\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5547 - accuracy: 0.7310\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5550 - accuracy: 0.7295\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5534 - accuracy: 0.7287\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5528 - accuracy: 0.7290\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5517 - accuracy: 0.7294\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5516 - accuracy: 0.7304\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5513 - accuracy: 0.7287\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5497 - accuracy: 0.7313\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5523 - accuracy: 0.7298\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5495 - accuracy: 0.7299\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7313\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5495 - accuracy: 0.7310\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7313\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5488 - accuracy: 0.7305\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7313\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7300\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7315\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5473 - accuracy: 0.7317\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5466 - accuracy: 0.7317\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7324\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5469 - accuracy: 0.7324\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7325\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7324\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7312\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7323\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7318\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7344\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5460 - accuracy: 0.7320\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7336\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7332\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5448 - accuracy: 0.7330\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7328\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7327\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7327\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5444 - accuracy: 0.7353\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5441 - accuracy: 0.7336\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7332\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5443 - accuracy: 0.7315\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5435 - accuracy: 0.7336\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7324\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5433 - accuracy: 0.7331\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5430 - accuracy: 0.7330\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7343\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5433 - accuracy: 0.7336\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "neural_net_trained_model_A3 = neural_net_A3.fit(X_train_scaled, y_train, epochs=50)\n",
    "# The simpler, shallower, single hidden layer A3 model appears to have performed nearly as well in training as the more complicated two hidden layer model.  Although the single hidden layer A3 model used more neurons in the first hidden layer (348) than the A2 model (58), the A2 model was more complicated and in aggregate made use of more neurons across its hidden layers (two layers independently combining to yield 58 times 29 neuron branches, or 1682 neuron combinations in the A2 model).\n",
    "# It will be interesting to next evaluate the four trained models in testing, using unseen data, but for now we prefer the A3 model for its power and ability to get the job done in training using a simpler and more efficient design and fewer resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: After finishing your models, display the accuracy scores achieved by each model, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Testing and Training Results Summary:\n",
      "268/268 - 1s - loss: 4.4750 - accuracy: 0.7082 - 829ms/epoch - 3ms/step\n",
      "\n",
      "Test Results:\n",
      "Loss: 4.475027561187744, Accuracy: 0.7082215547561646\n",
      "\n",
      "Available keys from train history dictionary: dict_keys(['loss', 'accuracy'])\n",
      "\n",
      "Train Results:\n",
      "Loss: 4.507335186004639, Accuracy: 0.7061887979507446\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model Testing and Training Results Summary:\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = neural_net.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model test loss and accuracy results\n",
    "print(f\"\\nTest Results:\\nLoss: {model_loss}, Accuracy: {model_accuracy}\\n\")\n",
    "\n",
    "# Review the available keys for the train history dictionary\n",
    "print(f\"Available keys from train history dictionary: {neural_net_trained_model_A1.history.keys()}\\n\")\n",
    "\n",
    "# Display the model train loss and accuracy results\n",
    "print(f\"Train Results:\\nLoss: {neural_net_trained_model.history['loss'][-1]}, Accuracy: {neural_net_trained_model.history['accuracy'][-1]}\")\n",
    "\n",
    "# Interesting to observe in this particular training iteration that the test results turned out superior to the actual training.  Other training iterations of this model did not generally produce this directional result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 1 Testing and Training Results Summary (A1):\n",
      "268/268 - 1s - loss: 0.5935 - accuracy: 0.7292 - 912ms/epoch - 3ms/step\n",
      "\n",
      "Test Results:\n",
      "Loss: 0.5935436487197876, Accuracy: 0.7292128205299377\n",
      "\n",
      "Train Results:\n",
      "Loss: 0.6160327792167664, Accuracy: 0.7318068742752075\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 1 Testing and Training Results Summary (A1):\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = neural_net_A1.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model test loss and accuracy results\n",
    "print(f\"\\nTest Results:\\nLoss: {model_loss}, Accuracy: {model_accuracy}\\n\")\n",
    "\n",
    "# Display the model train loss and accuracy results\n",
    "print(f\"Train Results:\\nLoss: {neural_net_trained_model_A1.history['loss'][-1]}, Accuracy: {neural_net_trained_model_A1.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 2 Testing and Training Results Summary (A2):\n",
      "268/268 - 1s - loss: 0.5565 - accuracy: 0.7286 - 927ms/epoch - 3ms/step\n",
      "\n",
      "Test Results:\n",
      "Loss: 0.5565388202667236, Accuracy: 0.7286297082901001\n",
      "\n",
      "Train Results:\n",
      "Loss: 0.5375846028327942, Accuracy: 0.7364329099655151\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 2 Testing and Training Results Summary (A2):\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = neural_net_A2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model test loss and accuracy results\n",
    "print(f\"\\nTest Results:\\nLoss: {model_loss}, Accuracy: {model_accuracy}\\n\")\n",
    "\n",
    "# Display the model train loss and accuracy results\n",
    "print(f\"Train Results:\\nLoss: {neural_net_trained_model_A2.history['loss'][-1]}, Accuracy: {neural_net_trained_model_A2.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 3 Testing and Training Results Summary (A3):\n",
      "268/268 - 1s - loss: 0.5618 - accuracy: 0.7291 - 789ms/epoch - 3ms/step\n",
      "\n",
      "Test Results:\n",
      "Loss: 0.5617796182632446, Accuracy: 0.7290962338447571\n",
      "\n",
      "Train Results:\n",
      "Loss: 0.6160327792167664, Accuracy: 0.7318068742752075\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 3 Testing and Training Results Summary (A3):\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = neural_net_A3.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model test loss and accuracy results\n",
    "print(f\"\\nTest Results:\\nLoss: {model_loss}, Accuracy: {model_accuracy}\\n\")\n",
    "\n",
    "# Display the model train loss and accuracy results\n",
    "print(f\"Train Results:\\nLoss: {neural_net_trained_model_A1.history['loss'][-1]}, Accuracy: {neural_net_trained_model_A1.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save each of your alternative models as an HDF5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bozmbp18/Tresorit/Boz & Company LLC/IAR/Todd Meier/Education/Columbia Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_13/Homework/neural-networks-challenge/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for the first alternative model\n",
    "file_nm_path = Path('Resources/AlphabetSoup_A1.h5')\n",
    "# Alternatively, set the file name path to the native .keras file format\n",
    "file_nm_path_alt = Path('Resources/AlphabetSoup_A1.keras')\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "neural_net_A1.save(file_nm_path)\n",
    "# Alternatively, export to the native .keras file format\n",
    "neural_net_A1.save(file_nm_path_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the second alternative model\n",
    "file_nm_path = Path('Resources/AlphabetSoup_A2.h5')\n",
    "# Alternatively, set the file name path to the native .keras file format\n",
    "file_nm_path_alt = Path('Resources/AlphabetSoup_A2.keras')\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "neural_net_A2.save(file_nm_path)\n",
    "# Alternatively, export to the native .keras file format\n",
    "neural_net_A2.save(file_nm_path_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the third alternative model\n",
    "file_nm_path = Path('Resources/AlphabetSoup_A3.h5')\n",
    "# Alternatively, set the file name path to the native .keras file format\n",
    "file_nm_path_alt = Path('Resources/AlphabetSoup_A3.keras')\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "neural_net_A3.save(file_nm_path)\n",
    "# Alternatively, export to the native .keras file format\n",
    "neural_net_A3.save(file_nm_path_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 1ms/step\n",
      "268/268 [==============================] - 0s 2ms/step\n",
      "268/268 [==============================] - 0s 2ms/step\n",
      "268/268 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Actual</th>\n",
       "      <th>Test_Pred_Orig</th>\n",
       "      <th>Test_Pred_A1</th>\n",
       "      <th>Test_Pred_A2</th>\n",
       "      <th>Test_Pred_A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.029622</td>\n",
       "      <td>0.762729</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.780832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176792</td>\n",
       "      <td>0.205197</td>\n",
       "      <td>0.211591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>34.923698</td>\n",
       "      <td>1.263842</td>\n",
       "      <td>0.723186</td>\n",
       "      <td>0.849688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.029622</td>\n",
       "      <td>0.762729</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.780832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.146249</td>\n",
       "      <td>0.673407</td>\n",
       "      <td>0.657174</td>\n",
       "      <td>0.671644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330262</td>\n",
       "      <td>0.350684</td>\n",
       "      <td>0.332828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>0</td>\n",
       "      <td>20.434734</td>\n",
       "      <td>0.886507</td>\n",
       "      <td>0.775288</td>\n",
       "      <td>0.704376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>1</td>\n",
       "      <td>4.322459</td>\n",
       "      <td>0.874238</td>\n",
       "      <td>0.936948</td>\n",
       "      <td>0.910023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277309</td>\n",
       "      <td>0.230098</td>\n",
       "      <td>0.300466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>1</td>\n",
       "      <td>7.029622</td>\n",
       "      <td>0.762729</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.780832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8575 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Test_Actual  Test_Pred_Orig  Test_Pred_A1  Test_Pred_A2  Test_Pred_A3\n",
       "0               1        7.029622      0.762729      0.741522      0.780832\n",
       "1               0        0.000000      0.176792      0.205197      0.211591\n",
       "2               1       34.923698      1.263842      0.723186      0.849688\n",
       "3               1        7.029622      0.762729      0.741522      0.780832\n",
       "4               0        7.146249      0.673407      0.657174      0.671644\n",
       "...           ...             ...           ...           ...           ...\n",
       "8570            1        0.000000      0.330262      0.350684      0.332828\n",
       "8571            0       20.434734      0.886507      0.775288      0.704376\n",
       "8572            1        4.322459      0.874238      0.936948      0.910023\n",
       "8573            0        0.000000      0.277309      0.230098      0.300466\n",
       "8574            1        7.029622      0.762729      0.741522      0.780832\n",
       "\n",
       "[8575 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reviewing dataset of test predictions vs. target\n",
    "test_actuals = y_test\n",
    "test_predictions_all_df = test_actuals.rename(columns={'IS_SUCCESSFUL': 'Test_Actual'})\n",
    "test_predictions_all_df['Test_Pred_Orig'] = neural_net.predict(X_test_scaled)\n",
    "test_predictions_all_df['Test_Pred_A1'] = neural_net_A1.predict(X_test_scaled)\n",
    "test_predictions_all_df['Test_Pred_A2'] = neural_net_A2.predict(X_test_scaled)\n",
    "test_predictions_all_df['Test_Pred_A3'] = neural_net_A3.predict(X_test_scaled)\n",
    "test_predictions_all_df = test_predictions_all_df.reset_index(drop=True)\n",
    "display(test_predictions_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* `Within the context of the alternative models, the original model did not produce a terrible result, where training accuracy was inferior to the alternatives by just around 4.1% in the worst case (0.7062/0.7364-1): original vs A3 model).  Test loss and accuracy metrics were self-consistent and comparable to training with respect to each model, indicative of robust models out-of-sample.`\n",
    "\n",
    ">* `We believe the loss function for the original model appeared much worse, while simultaneously showing competitive accuracy against the alternative models, because the loss function was derived from the raw predictions versus actual, whereas the accuracy metric defaulted to binary accuracy, reflecting, or consistent with, the binary_crossentropy loss specification, which transformed and classified the raw predictions as a 0 or 1 class label, based on a default 0.5 threshold. (In other words, predictions below 0.5 were assigned the 0 label, whereas those above 0.5 were assigned the 1 label, and then accuracy calculated, yielding relatively competitive and consistent accuracy across all models, and which remained robust to testing.)`\n",
    "\n",
    ">* `References: https://keras.io/guides/training_with_built_in_methods/, https://visualstudiomagazine.com/articles/2018/08/30/neural-binary-classification-keras.aspx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bozmbp18/Tresorit/Boz & Company LLC/IAR/Todd Meier/Education/Columbia Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_13/Homework/neural-networks-challenge/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Sojourn.  Reviewing quickly performance of a traditional non-iterative supervised learning model to explain our venture funding data.\n",
    "# Classification with Support Vector Model:\n",
    "# Import SVM library\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate an SVM classification model\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the Data\n",
    "svc_model = svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Actual\n",
       "0               0       0\n",
       "1               1       1\n",
       "2               1       1\n",
       "3               1       1\n",
       "4               1       1\n",
       "...           ...     ...\n",
       "25719           0       0\n",
       "25720           1       1\n",
       "25721           0       0\n",
       "25722           0       0\n",
       "25723           0       0\n",
       "\n",
       "[25724 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review training data predictions\n",
    "y_train_predictions = svc_model.predict(X_train_scaled)\n",
    "train_results = pd.DataFrame({\"Prediction\": y_train_predictions, \"Actual\": y_train['IS_SUCCESSFUL']}).reset_index(drop=True)\n",
    "display(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVM SVC Model Train Score: 0.7339838283315192\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SVM SVC Model Test Score: 0.7286297376093295'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score the model as trained\n",
    "score_train = svc_model.score(X_train_scaled, y_train)\n",
    "display(f\"SVM SVC Model Train Score: {score_train}\\n\")\n",
    "\n",
    "# Score the model exposed to unseen test data\n",
    "score_test = svc_model.score(X_test_scaled, y_test)\n",
    "display(f\"SVM SVC Model Test Score: {score_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* `Traditional closed-form supervised learning model, using a support vector machine classifier, appeared to perform just as well as a more complex and resource-intensive neural net model.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
